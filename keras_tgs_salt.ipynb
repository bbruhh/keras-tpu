{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_tgs_salt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "HrwYWcoMY00C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the dependencies we need\n",
        "!pip install tqdm\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_XHzgYuZHMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6YTX_mHH_q4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Check the TPU we are using\n",
        "try:\n",
        "  device_name = os.environ['COLAB_TPU_ADDR']\n",
        "  TPU_ADDRESS = 'grpc://' + device_name\n",
        "  print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "  \n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)\n",
        "\n",
        "except KeyError:\n",
        "  print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9WtCXg_0aHaA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Upload our Kaggle API token\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2z1Q0Mnpc7YE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure we have uploaded the file successfully\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8kUvUsFdHK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2GRpe9mGda9y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's now download our dataset\n",
        "!kaggle competitions download -c tgs-salt-identification-challenge"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InnJQ1W9eT7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# And we'll need those training images unzipped\n",
        "!ls\n",
        "!mkdir train\n",
        "!mkdir test\n",
        "!unzip -q train.zip -d train\n",
        "!unzip -q test.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7jKIdlH3gaFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Helper functions for data processing\n",
        "img_size_ori = 101\n",
        "img_size_target = 128\n",
        "\n",
        "def upsample(img):\n",
        "    if img_size_ori == img_size_target:\n",
        "        return img\n",
        "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
        "\n",
        "\n",
        "def downsample(img):\n",
        "    if img_size_ori == img_size_target:\n",
        "        return img\n",
        "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GKgpMbL3gbp_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "train_df = pd.read_csv(\"./train.csv\", index_col=\"id\", usecols=[0])\n",
        "depths_df = pd.read_csv(\"./depths.csv\", index_col=\"id\")\n",
        "train_df = train_df.join(depths_df)\n",
        "test_df = depths_df[~depths_df.index.isin(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5Rs074Hi9NB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"images\"] = [np.array(load_img(\"./train/images/{}.png\".format(idx), color_mode = \"grayscale\")) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSCh6OUHkbm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"masks\"] = [np.array(load_img(\"./train/masks/{}.png\".format(idx), color_mode = \"grayscale\")) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JyLfDfQMknvS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKSfmStTlG4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cov_to_class(val):    \n",
        "    for i in range(0, 11):\n",
        "        if val * 10 <= i :\n",
        "            return i\n",
        "        \n",
        "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bUsdtjWlKr0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
        "    train_df.index.values,\n",
        "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
        "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
        "    train_df.coverage.values,\n",
        "    train_df.z.values,\n",
        "    test_size=0.2, stratify=train_df.coverage_class, random_state=1337)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojwNsiAcJMA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data augmentation by flipping the image\n",
        "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
        "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3il94PclT_z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Buid the U-net model\n",
        "def build_model(input_layer, start_neurons):\n",
        "    # 128 -> 64\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = Dropout(0.25)(pool1)\n",
        "\n",
        "    # 64 -> 32\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = Dropout(0.5)(pool2)\n",
        "\n",
        "    # 32 -> 16\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = Dropout(0.5)(pool3)\n",
        "\n",
        "    # 16 -> 8\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(0.5)(pool4)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
        "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n",
        "\n",
        "    # 8 -> 16\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4 = Dropout(0.5)(uconv4)\n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
        "\n",
        "    # 16 -> 32\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])\n",
        "    uconv3 = Dropout(0.5)(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
        "\n",
        "    # 32 -> 64\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "    uconv2 = Dropout(0.5)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
        "\n",
        "    # 64 -> 128\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    uconv1 = Dropout(0.5)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
        "\n",
        "    #uconv1 = Dropout(0.5)(uconv1)\n",
        "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    \n",
        "    return output_layer\n",
        "\n",
        "input_layer = Input((img_size_target, img_size_target, 1))\n",
        "output_layer = build_model(input_layer, 16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qQ_qgtrml0E7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model(input_layer, output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAKDMuwRmCLh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Transfer the model on TPU\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_ADDRESS)\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAHeniYCmhuP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wHi9-1jympz9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YbyhLPndm6fv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start our training\n",
        "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint(\"./keras.model\", save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 32\n",
        "\n",
        "history = tpu_model.fit(x_train, y_train,\n",
        "                        validation_data=[x_valid, y_valid], \n",
        "                        epochs=epochs,\n",
        "                        batch_size=batch_size,\n",
        "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "46MNAtBiu9_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model(\"./keras.model\")\n",
        "preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\n",
        "preds_valid = np.array([downsample(x) for x in preds_valid])\n",
        "y_valid_ori = np.array([train_df.loc[idx].masks for idx in ids_valid])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fO5GhT5wyyhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "    \n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
        "\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
        "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "\n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6uU9vIWzjcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Find the best threshold\n",
        "thresholds = np.linspace(0, 1, 50)\n",
        "ious = np.array([iou_metric_batch(y_valid_ori, np.int32(preds_valid > threshold)) for threshold in tqdm(thresholds)])\n",
        "threshold_best_index = np.argmax(ious[9:-10]) + 9\n",
        "iou_best = ious[threshold_best_index]\n",
        "threshold_best = thresholds[threshold_best_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAyw5PCszsPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(thresholds, ious)\n",
        "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_d1m1lK0PEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Source https://www.kaggle.com/bguberfain/unet-with-depth\n",
        "def RLenc(img, order='F', format=True):\n",
        "    \"\"\"\n",
        "    img is binary mask image, shape (r,c)\n",
        "    order is down-then-right, i.e. Fortran\n",
        "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
        "\n",
        "    returns run length as an array or string (if format is True)\n",
        "    \"\"\"\n",
        "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
        "    runs = []  ## list of run lengths\n",
        "    r = 0  ## the current run length\n",
        "    pos = 1  ## count starts from 1 per WK\n",
        "    for c in bytes:\n",
        "        if (c == 0):\n",
        "            if r != 0:\n",
        "                runs.append((pos, r))\n",
        "                pos += r\n",
        "                r = 0\n",
        "            pos += 1\n",
        "        else:\n",
        "            r += 1\n",
        "\n",
        "    # if last run is unsaved (i.e. data ends with 1)\n",
        "    if r != 0:\n",
        "        runs.append((pos, r))\n",
        "        pos += r\n",
        "        r = 0\n",
        "\n",
        "    if format:\n",
        "        z = ''\n",
        "\n",
        "        for rr in runs:\n",
        "            z += '{} {} '.format(rr[0], rr[1])\n",
        "        return z[:-1]\n",
        "    else:\n",
        "        return runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_gCEu020QFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test = np.array([upsample(np.array(load_img(\"./test/images/{}.png\".format(idx), grayscale=True))) / 255 for idx in tqdm(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtjwyHHl0sET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds_test = model.predict(x_test)\n",
        "pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm(test_df.index.values))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjWTdUGR1RBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
        "sub.index.names = ['id']\n",
        "sub.columns = ['rle_mask']\n",
        "sub.to_csv('submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}